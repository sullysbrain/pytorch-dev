ARG BASE_IMAGE="nvidia/cuda:12.9.1-cudnn-devel-ubuntu24.04"
ARG USE_CUDA="true"
ARG DEBIAN_FRONTEND=noninteractive
FROM ${BASE_IMAGE}

ENV WORKDIR=/workspace \
    COMFYUI_PATH=/opt/ComfyUI \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# --- User/Group defaults used by devcontainer features and by you ---
# ARG USER=comfy
# ARG USER_UID=1000
# ARG USER_GID=1000
# RUN groupadd -g ${USER_GID} ${USER} || true \
#  && id -u ${USER} >/dev/null 2>&1 || useradd -m -s /bin/bash -u ${USER_UID} -g ${USER_GID} ${USER}
# ENV USER=${USER}

# Use the PyTorch cu129 index only when building the CUDA-enabled image.
ARG PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cu129"

WORKDIR ${WORKDIR}

# System packages
RUN --mount=type=cache,target=/var/cache/apt \
    apt-get update \
    && apt-get upgrade -y \
    && apt-get install -y --no-install-recommends \
       python3.10 python3-pip python3-venv \
       tini jq ca-certificates git build-essential cmake ninja-build wget curl aria2 ffmpeg \
       libgl1-mesa-dev libopengl0 gdb \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Ensure /usr/bin/python3 and pip point to python0 and pip for consistency
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 \
 && python3 -m pip install --upgrade pip setuptools wheel



# RUN groupadd -g ${USER_GID} ${USER} \
#  && useradd -m -s /bin/bash -u ${USER_UID} -g ${USER_GID} ${USER}

# Safe user/group creation if not already created by features
# RUN set -eux; \
#     if ! getent group "${USER_GID}" >/dev/null; then groupadd -g "${USER_GID}" "${USER}"; fi; \
#     if ! id -u "${USER}" >/dev/null 2>&1; then useradd -m -s /bin/bash -u "${USER_UID}" -g "${USER_GID}" "${USER}"; fi



# Clone ComfyUI early so layer is cached; pinable via build-arg later
ARG COMFYUI_VERSION=master
RUN git clone --single-branch https://github.com/comfyanonymous/ComfyUI.git ${COMFYUI_PATH} \
 && git -C ${COMFYUI_PATH} fetch --all --tags --prune \
 && git -C ${COMFYUI_PATH} reset --hard ${COMFYUI_VERSION}

# Copy unified requirements file (ensure it exists in build context)
COPY requirements.txt ${WORKDIR}/requirements.txt

# Install PyTorch (CUDA when requested) explicitly before building xformers,
# then install requirements and xformers. Use cache mounts for pip.
RUN --mount=type=cache,target=/root/.cache/pip \
        python3 -m pip install --upgrade pip setuptools wheel \
        && if [ "${USE_CUDA}" = "true" ]; then \
                 echo "Installing CUDA PyTorch from index ${PIP_EXTRA_INDEX_URL}"; \
                 python3 -m pip install --index-url ${PIP_EXTRA_INDEX_URL} --no-cache-dir --prefer-binary "torch" "torchvision" "torchaudio"; \
             else \
                 echo "Installing CPU PyTorch"; \
                 python3 -m pip install --no-cache-dir --prefer-binary "torch" "torchvision" "torchaudio"; \
             fi \
        && python3 -m pip install --no-cache-dir -r ${WORKDIR}/requirements.txt || true \
        && python3 -m pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers || true

RUN python3 -m pip install --upgrade pip \
    && python3 -m pip install --no-cache-dir -r ${COMFYUI_PATH}/requirements.txt \
    && python3 -m pip install --no-cache-dir pyyaml

# Ensure permissions for volumes and workspace
RUN mkdir -p /models /data \
#  && chown -R ${USER}:${USER} /models /data ${COMFYUI_PATH} ${WORKDIR} \
 && chmod -R 775 ${COMFYUI_PATH} /models /data


# Make sure this matches where you cloned ComfyUI
ENV COMFYUI_PATH=/opt/ComfyUI

# Persist the standard ComfyUI dirs
VOLUME ["${COMFYUI_PATH}/user", "${COMFYUI_PATH}/output", "${COMFYUI_PATH}/models", "${COMFYUI_PATH}/custom_nodes"]

EXPOSE 8188

# Run as root so mounted volumes are always writable
# USER root

# Start ComfyUI directly (CPU on Mac/ARM; set USE_CUDA via args if you want a CUDA path elsewhere)
ENTRYPOINT ["/usr/bin/tini","--","python3","-u","/opt/ComfyUI/main.py","--listen","127.0.0.1","--port","8188","--cpu","--disable-xformers"]

